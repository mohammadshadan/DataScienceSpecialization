apply(pokemon, 2, sd)
pokemon.scaled <- scale(pokemon)
hclust.pokemon <- hclust(dist(pokemon.scaled), method="complete")
plot(hclust.pokemon)
data = iris[,-5]
head(data)
km <- kmeans(data, centers = 3)
km
library(cluster)
data(xclara)
head(xclara)
km <- kmeans(xclara,3)
km
km$cl
sk <- silhouette(km$cl, dissE)
dissE <- daisy(xclara)
sk <- silhouette(km$cl, dissE)
plot(sk)
window()
windows()
plot(sk)
head(xclara)
dissE <- daisy(xclara)
sk <- silhouette(km$cl, dissE)
windows()
plot(sk)
km
km[1]
km[2]
km
km[5]
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1903/datasets/WisconsinCancer.csv"
wisc.df <- read.csv(url)
wisc.data[1:6, 1:5]
wisc.df[1:6, 1:5]
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1903/datasets/WisconsinCancer.csv"
wisc.df <- read.csv(url)
wisc.data <- as.matrix(wisc.df)
row.names(wisc.data) <- wisc.df$id
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
head(wisc.data)
wisc.data <- as.matrix(wisc.df[3:32])
row.names(wisc.data) <- wisc.df$id
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
head(wisc.data)
head(wisc.df)
dim(wisc.data)
colnames(wisc.data)
table(diagnosis)
grep("_mean", colnames(wisc.data))
length(grep("_mean", colnames(wisc.data)))
colnames(wisc.data)[(grep("_mean", colnames(wisc.data)))]
ls()
colMeans(wisc.data)
apply(wisc.data, 2, sd)
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
biplot(wisc.pr)
plot(wisc.pr$rotation[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$rotation[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$rotation[, c(1, 4)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC4")
biplot(wisc.pr)
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$x[, c(1, 4)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
par(mfrow = c(1, 2))
pr.var <- wisc.pr$sdev^2
pve <- pr.var/sum(pr.var)
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cummulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
wise.pr$rotation
wisc.pr$rotation[rownames(wisc.pr$rotation)=="concave.points_mean",]
wisc.pr$rotation[rownames(wisc.pr$rotation)=="concave.points_mean",][1]
round(colMeans(wisc.data),1)
round(apply(wisc.data,2,sd),1)
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist, method="complete")
round(colMeans(data.scaled),1)
round(apply(data.scaled,2,sd),1)
plot(wisc.hclust)
plot(wisc.hclust)
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
wisc.km <- kmeans(scale(wisc.data), centers=2, nstart=20)
table(wisc.km$cluster, diagnosis)
table(wisc.km$cluster, wisc.hclust.clusters)
pve <- pr.var/sum(pr.var)
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cummulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
summary(wisc.pr)
class(summary(wisc.pr))
pve
len(pve)
length(pve)
for(i in 1:length(pve)){
paste("Num of Components", i, "Variance", cumsum(pve[1:i]))
}
print(paste("Num of Components", i, "Variance", cumsum(pve[1:i])))
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", round(cumsum(pve[1:i]),1)))
}
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", round(cumsum(pve[1:i]))))
}
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", cumsum(pve[1:i])))
}
head(mtcars)
colMeans(mtcars)
data.frame(colMeans(mtcars))
apply(mtcars, 2, sd)
data.frame(apply(mtcars, 2, sd))
mtcars_scaled <- scale(mtcars)
head(mtcars_scaled)
data.frame(colMeans(mtcars_scaled))
data.frame(apply(mtcars_scaled, 2, sd))
center(mtcars)
?scale
new_text <- "DataCamp is the first online learning platform that focuses on building the best learning experience specifically for Data Science. We have offices in Boston and Belgium and to date, we trained over 250,000 (aspiring) data scientists in over 150 countries. These data science enthusiasts completed more than 9 million exercises. You can take free beginner courses, or subscribe for $25/month to get access to all premium courses."
library(qdap)
install.packages("qdap")
library(qdap)
library(qdap)
install.packages("qdapRegex")
library(qdapRegex)
library(qdap)
install.packages("‘qdapTools’")
library(qdapRegex)
library(qdap)
library(qdapTool)
library(qdapTools)
install.packages("qdapTools")
library(qdapRegex)
library(qdapTools)
library(qdap)
install.packages("qdap")
library(gender)
library(qdap)
print(new_text)
term_count <- freq_terms(new_text,10)
plot(term_count)
library(plyr)
a <- airquality
names(a)[colMeans(is.na(a))>0]
library(ROSE)
install.packages("ROSE")
data(hacide)
library(ROSE)
data(hacide)
str(hacide.train)
table(hacide.train$cls)
prop.table(table(hacide.train$cls))
treeimb <- rpart(cls ~ ., data = hacide.train)
library(rpart)
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test)
str(pred.treeimb)
summary(pred.treeimb)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F)
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = T)
pred.treeimb
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F)
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = T)
hacide.test$cls
head((hacide.train))
table(hacide.train$cls)
str(hacide.test)
head((hacide.test))
table(hacide.test$cls)
table(hacide.train$cls)
library(caret)
rfimb <- train(cls~., data=hacide.train)
str(hacide.train)
pred.rfimb <- predict(rfimb, newdata = hacide.test)
confusionMatrix(pred.treeimb[,2],hacide.test$cls)
accuracy.meas(hacide.test$cls, pred.rfimb[,2])
rm(list=ls())
library(ROSE)
data(hacide)
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test)
pred.treeimb
hacide.test
library(caret)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit
head(training)
head(testing)
pred <- predict(modFit,testing)
pred
head((hacide.train))
str(hacide.train)
rfimb <- train(cls~., method="rf",data=hacide.train)
pred.rfimb <- predict(rfimb, newdata = hacide.test)
pred.rfimb
accuracy.meas(hacide.test$cls, pred.rfimb)
roc.curve(hacide.test$cls, pred.treeimb, plotit = F)
dim(hacide.test$cls)
length(hacide.test$cls)
roc.curve(hacide.test$cls, pred.rfimb, plotit = F)
roc.curve(hacide.test$cls, pred.rfimb, plotit = T)
confusionMatrix(pred.rfimb,hacide.test$cls)
accuracy.meas(hacide.test$cls, pred.rfimb)
treeimb1 <- train(cls ~ .,method="rpart", data = hacide.train)
pred.treeimb1 <- predict(treeimb1, newdata = hacide.test)
pred.treeimb1
accuracy.meas(hacide.test$cls, pred.treeimb1)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
treeimb <- rpart(cls ~ ., data = hacide.train, type="class")
treeimb <- rpart(cls ~ ., data = hacide.train, type="class")
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test, tpye="class")
pred.treeimb
head(hacide.train)
head(hacide.test)
head(cbind(hacide.test$cls, pred.treeimb[,2]))
pred.treeimb
head(pred.treeimb)
confusionMatrix(hacide.test$cls, pred.treeimb[,2])
confusionMatrix(hacide.test$cls, pred.treeimb)
treeimb1 <- train(cls ~ .,method="rpart", data = hacide.train)
pred.treeimb1 <- predict(treeimb1, newdata = hacide.test)
treeimb_c <- train(cls ~ .,method="rpart", data = hacide.train)
pred.treeimb_c <- predict(treeimb1, newdata = hacide.test)
accuracy.meas(hacide.test$cls, pred.treeimb_c)
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = F) #Without Plot
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = T) #With Plot
confusionMatrix(pred.treeimb_c, hacide.test$cls)
accuracy.meas(pred.treeimb_c,hacide.test$cls)
accuracy.meas(hacide.test$cls, pred.treeimb_c)
confusionMatrix(pred.treeimb_c, hacide.test$cls)
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = F) #Without Plot
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = T) #With Plot
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test, tpye="class")
head(pred.treeimb)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F) #Without Plot
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = T) #With Plot
rfimb_c <- train(cls~., method="rf",data=hacide.train)
pred.rfimb_c <- predict(rfimb_c, newdata = hacide.test)
accuracy.meas(hacide.test$cls, pred.rfimb_c)
confusionMatrix(pred.rfimb_c, hacide.test$cls)
roc.curve(hacide.test$cls, pred.rfimb_c, plotit = F)
roc.curve(hacide.test$cls, pred.rfimb_c, plotit = T)
?randomForest
help(randomForest)
??randomForest
library(stringr)
?str_view
awards <- c("Won 1 Oscar.",
"Won 1 Oscar. Another 9 wins & 24 nominations.",
"1 win and 2 nominations.",
"2 wins & 3 nominations.",
"Nominated for 2 Golden Globes. 1 more win & 2 nominations.",
"4 wins & 1 nomination.")
awards
str_view(awards, pattern=".*\\s([0-9]+)\\snomination.*$")
?regex
str_view(awards, pattern=".*\\s([0-9]+)\\snomination.*$")
str_view(awards, pattern="&.*\\s([0-9]+)\\snomination.*$")
str_view(awards, pattern=".\\s([0-9]+)\\snomination.*$")
str_view(awards, pattern="\\s([0-9]+)\\snomination.*$")
awards <- c("Won 1 Oscar.",
"Won 1 Oscar. Another 9 wins & 24 nominations.",
"1 win and 2 nominations.",
"2 wins & 3 nominations.",
"Nominated for 2 Golden Globes. 1 more win & 2 nominations.",
"4 wins & 1 nomination.")
awards
str_view(awards, pattern=".*\\s([0-9]+)\\snomination.*$")
str_view(awards, pattern="\\s([0-9]+)\\snomination.*$")
str_view(awards, pattern="&.*\\s([0-9]+)\\snomination.*$")
# Get the current date: today
today <- Sys.Date()
# See what today looks like under the hood
unclass(today)
# Get the current time: now
now <- Sys.time()
# See what now looks like under the hood
unclass(now)
# Definition of character strings representing times
str1 <- "May 23, '96 hours:23 minutes:01 seconds:45"
str2 <- "2012-3-12 14:23:08"
# Convert the strings to POSIXct objects: time1, time2
time1 <- as.POSIXct(str1, format = "%B %d, '%y hours:%H minutes:%M seconds:%S")
time2 <- as.POSIXct(str2, format = "%Y-%m-%d %H:%M:%S")
# Convert times to formatted strings
format(time1, "%M")
format(time2, "%I:%M %p")
c(day1, day2, day3, day4, day5) <- c("2017-05-01" ,"2017-05-03", "2017-05-08" ,"2017-05-14" ,"2017-05-19")
day1 =as.Date("2017-05-01")
day2 =as.Date("2017-05-03")
day3 =as.Date("2017-05-08")
day4 =as.Date("2017-05-14")
day5 =as.Date("2017-05-19")
day5-day1
pizza <- c(day1, day2, day3, day4, day5)
day_diff <- diff(pizza)
mean(day_diff)
astro <- c("20-Mar-2015", "25-Jun-2015", "23-Sep-2015", "22-Dec-2015")
names(astro) <- c('spring'  ,     'summer',          'fall'  ,      'winter')
astro
meteo = c("March 1, 15",      "June 1, 15" ,"September 1, 15" , "December 1, 15")
names(meteo)=c('spring'   ,         'summer'        ,      'fall'  ,          'winter')
meteo
astro_dates <- as.Date(astro, "%d-%b-%Y")
meteo_dates <- as.Date(meteo, "%B %d, %y")
print(max(abs(astro_dates-meteo_dates)))
getwd()
setwd("~/GitHub/LearningPython/Datacamp/R - Correlation and Regression")
Anscombe <- read.table("Anscombe.txt")
head(Anscombe)
Anscombe <- read.table("Anscombe.txt", header=TRUE)
head(Anscombe)
str(Anscombe)
ggplot(data = Anscombe, aes(x = x, y = y)) +
geom_point() +
facet_wrap(~ set)
library(ggplot2)
ggplot(data = Anscombe, aes(x = x, y = y)) +
geom_point() +
facet_wrap(~ set)
Anscombe %>%
group_by(set) %>%
summarize(N = n(), mean(x), sd(x), mean(y), sd(y), cor(x,y))
library(dplyr)
Anscombe %>%
group_by(set) %>%
summarize(N = n(), mean(x), sd(x), mean(y), sd(y), cor(x,y))
noise <- read.table("noise.txt", header = TRUE)
head(noise)
ggplot(noise, aes(x,y)) + geom_point() + facet_wrap(~z)
noise_summary <- noise %>%
group_by(z) %>%
summarize(N = n(), spurious_cor = cor(x, y))
noise_summary %>%
filter(abs(spurious_cor) > 0.2)
bdims_summary <- read.delim("clipboard")
head(bdims_summary)
bdims_summary <- read.table("clipboard")
head(bdims_summary)
bdims_summary <- read.table("clipboard", header = TRUE)
head(bdims_summary)
bdims_summary
print(bdims_summary)
bdims_summary %>%
mutate(slope = r*sd_wgt/sd_hgt,
intercept = mean_wgt - (r*sd_wgt/sd_hgt)*mean_hgt)
library(galton)
library(readxl)
Galton_men <- read_excel("Galton_men.xlsx", sheet=1)
Galton_men <- read_excel("Galton_men.xlsx", sheet=1, header=TRUE)
Galton_men <- read_excel("Galton_men.xlsx", sheet=1)
dim(Galton_men)
Galton_women <- read_excel("Galton_women.xlsx", sheet=1)
dim(Galton_women)
head(Galton_men)
head(Galton_women)
ggplot(data = Galton_men, aes(x = father, y = height)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
geom_smooth(method = "lm", se = FALSE)
ggplot(data = Galton_women, aes(x = mother, y = height)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
geom_smooth(method = "lm", se = FALSE)
bdims <- read_excel("bdims.xlsx", sheet=1)
head(bdims)
dim(bdims)
bdims <- read_excel("bdims.xlsx", sheet=1)
head(bdims)
dim(bdims)
add_line <- function (my_slope) {
bdims_summary <- bdims %>%
summarize(N = n(), r = cor(hgt, wgt),
mean_hgt = mean(hgt), mean_wgt = mean(wgt),
sd_hgt = sd(hgt), sd_wgt = sd(wgt)) %>%
mutate(true_slope = r * sd_wgt / sd_hgt,
true_intercept = mean_wgt - true_slope * mean_hgt)
p <- ggplot(data = bdims, aes(x = hgt, y = wgt)) +
geom_point() +
geom_point(data = bdims_summary,
aes(x = mean_hgt, y = mean_wgt),
color = "red", size = 3)
my_data <- bdims_summary %>%
mutate(my_slope = my_slope,
my_intercept = mean_wgt - my_slope * mean_hgt)
p + geom_abline(data = my_data,
aes(intercept = my_intercept, slope = my_slope), color = "dodgerblue")
}
add_line(my_slope = 5)
add_line(my_slope = 1)
mlbBat10 <- read_excel("mlbBat10.xlsx", sheet=1)
mammals <- read_excel("mammals.xlsx", sheet=1)
dim(mlbBat10)
dim(mammals)
names(mammals)
names(mlbBat10)
lm(wgt ~ hgt, data = bdims)
# Linear model for SLG as a function of OBP
lm(SLG~OBP, data=mlbBat10)
# Log-linear model for body weight as a function of brain weight
lm(log(BodyWt)~log(BrainWt), data=mammals)
attributes(lm(wgt ~ hgt, data = bdims))
head(iris)
km <- kmeans(iris[,-5], k=3)
?kmeans
km <- kmeans(iris[,-5], centers=3)
attributes(km)
str(km)
attributes(lm(wgt ~ hgt, data = bdims))
lm1 <- attributes(lm(wgt ~ hgt, data = bdims))
mod <- lm(wgt ~ hgt, data = bdims)
coef(mod)
coefficients(mod)
summary(mod)
library(broom)
bdims_tidy <- augment(mod)
glimpse(bdims_tidy)
head(bdims_tidy)
ben = data.frame(wgt=74.8, hgt=182.8)
print(ben)
print(ben)
predict(mod, newdata=ben)
coef(mod)[2]
coefs <- data.frame((Intercept)=coef(mod)[1], slope=coef(mod)[2])
coefs <- data.frame('(Intercept)'=coef(mod)[1], slope=coef(mod)[2])
coefs
summary(mod)
bdims_tidy %>%
summarize(var_y = var(wgt), var_e = var(.resid)) %>%
mutate(R_squared = 1-var_e/var_y)
bdims_tidy %>%
summarize(var_y = var(wgt), var_e = var(.resid)) %>%
mutate(R_squared = 1-var_e/var_y)
mod_null <- lm(wgt ~ 1, data = dbims)
mod_null <- lm(wgt ~ 1, data = bdims)
mod_null <- augment(mod_null)
glimpse(mod_null)
head(bdims)
glimpse(bdims_tidy)
head(bdims_tidy)
mod1 <- lm(wgt ~ 1, data = bdims)
mod_null <- augment(mod1)
glimpse(mod_null)
head(bdims)
mod_null <- augment(mod1, bdims)
glimpse(mod_null)
mod2 <- lm(wgt ~ hgt, data = bdims)
mod_null <- augment(mod2, bdims)
mod1 <- lm(wgt ~ 1, data = bdims)
mod_null <- augment(mod1, bdims)
glimpse(mod_null)
mod2 <- lm(wgt ~ hgt, data = bdims)
mod_hgt <- augment(mod2, bdims)
glimpse(mod_hgt)
mod_null %>%
summarize(SSE = var(.resid))
mod_hgt %>%
summarize(SSE = var(.resid))
mod_hgt %>%
summarize(SSE = var(.resid))
mod_hgt %>%
summarize(SSE = sum(.resid^2))
mod_null %>%  summarize(SSE = sum(.resid^2))
mod_hgt %>%
summarize(SSE = sum(.resid^2))
mod_null %>%
summarize(SSE = var(.resid))
mod_hgt %>%
summarize(SSE = var(.resid))
86.46839/178.1094
mod_null %>%  summarize(SSE = sum(.resid^2))
mod_hgt %>%
summarize(SSE = sum(.resid^2))
43753.01/90123.34
mod_null %>%  summarize(SSE = sum(.resid^2)) / mod_hgt %>% summarize(SSE = sum(.resid^2))
mod_hgt %>% summarize(SSE = sum(.resid^2)) / mod_null %>%  summarize(SSE = sum(.resid^2))
mod_hgt %>% summarize(SSE = sum(.resid^2)) / mod_null %>%  summarize(SSE = sum(.resid^2))
mod_hgt %>%   summarize(SSE = var(.resid)) / mod_null %>% summarize(SSE = var(.resid))
mod_hgt %>%   summarize(SSE = var(.resid)) / mod_null %>% summarize(SSE = var(.resid))
mod_hgt %>% summarize(SSE = sum(.resid^2)) / mod_null %>%  summarize(SSE = sum(.resid^2))
var(.resid))
mod_hgt %>%   summarize(SSE = var(.resid))
mod_hgt %>% summarize(SSE = sum(.resid^2))
attributes(km)
tot.withinss(km)
km$tot.withinss
