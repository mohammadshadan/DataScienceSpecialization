prop_own = mean(HomeOwn == "Own")) %>%
homes %>%
mutate(HomeOwn_perm = sample(HomeOwn)) %>%
group_by(Gender) %>%
summarize(prop_own_perm = mean(HomeOwn_perm == "Own"),
prop_own = mean(HomeOwn == "Own"))
summarize(diff_perm = diff(prop_own_perm),
diff_orig = diff(prop_own))
homes %>%
mutate(HomeOwn_perm = sample(HomeOwn)) %>%
group_by(Gender) %>%
summarize(prop_own_perm = mean(HomeOwn_perm == "Own"),
prop_own = mean(HomeOwn == "Own")) %>%
summarize(diff_perm = diff(prop_own_perm),
diff_orig = diff(prop_own))
install.packages("hflights")
library(dplyr)
library(hflights)
head(hflights)
summary(hflights)
dim(hflights)
# Convert the hflights data.frame into a hflights tbl
hflights <- tbl_df(hflights)
# Display the hflights tbl
hflights
# Create the object carriers
carriers <- hflights$UniqueCarrier
str(hflights)
two <- c("AA", "AS")
lut <- c("AA" = "American",
"AS" = "Alaska",
"B6" = "JetBlue")
lut
two <- lut[two]
two
# Both the dplyr and hflights packages are loaded into workspace
lut <- c("AA" = "American", "AS" = "Alaska", "B6" = "JetBlue", "CO" = "Continental",
"DL" = "Delta", "OO" = "SkyWest", "UA" = "United", "US" = "US_Airways",
"WN" = "Southwest", "EV" = "Atlantic_Southeast", "F9" = "Frontier",
"FL" = "AirTran", "MQ" = "American_Eagle", "XE" = "ExpressJet", "YV" = "Mesa")
# Add the Carrier column to hflights
hflights$Carrier <- lut[hflights$UniqueCarrier]
# Glimpse at hflights
glimpse(hflights)
?hflights
library(psych)
bmi_cc <- read.clipboard()
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.delim("clipboard")
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.delim("clipboard")
bmi_cc
names(bmi_cc)
bmi_cc <- read.delim("clipboard", sep = " ")
bmi_cc <- read.delim("clipboard", sep = " ",header = TRUE)
bmi_cc <- read.delim("clipboard", sep = " ",header = TRUE)
bmi_cc
bmi_cc <- read.delim("clipboard",header = TRUE)
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.delim("clipboard",header = TRUE)
bmi_cc
library(tidyr)
separate(bmi_cc, Country_ISO..year..bmi_val, c("Country_ISO","year","bmi_val"))
separate(bmi_cc, Country_ISO..year..bmi_val, c("Country_ISO","year","bmi_val"), sep="...")
library(ggplot2)
data(diamonds)
head(diamonds)
str(diamonds)
q()
library (cluster)
library (vegan)
install.packages("vegan")
library (vegan)
data(varespec)
head(varespec)
dis = vegdist(varespec)
res = pam(dis,3) # or whatever your choice of clustering algorithm is
sil = silhouette (res$clustering,dis) # or use your cluster vector
plot(sil)
windows() # RStudio sometimes does not display silhouette plots correctly
plot(sil)
library (vegan)
library (cluster)
data(varespec)
dis = dist(varespec)^2
km <- kmeans(data, centers = 3)
data = iris[,-5]
km <- kmeans(data, centers = 3)
km
wss <- 0
for (i in 1:15) {
km.out <- kmeans(data, centers = i, nstart=20)
# Save total within sum of squares to wss variable
wss[i] <- km.out$tot.withinss
}
plot(1:15, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within groups sum of squares")
data = mtcars
wss <- 0
for (i in 1:15) {
km.out <- kmeans(data, centers = i, nstart=20)
# Save total within sum of squares to wss variable
wss[i] <- km.out$tot.withinss
}
plot(1:15, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within groups sum of squares")
head(data)
clip <- read.delim("clipboard")
head(clip)
rownames(clip)
class(clip)
clip <- read.delim("clipboard")
head(clip)
rownames(clip)
class(clip)
x <- read.delim("clipboard")
x
names(x)
hclust.complete <- hclust(dist(x), method="complete")
x <- read.delim("clipboard")
x
x <- read.delim("clipboard")
x
names(x)
x <- read.delim("clipboard")
x
names(x)
hclust.complete <- hclust(dist(x), method="complete")
hclust.average <- hclust(dist(x), method="average")
hclust.single <- hclust(dist(x), method="single")
plot(hclust.complete)
plot(hclust.average)
plot(hclust.single)
plot(hclust.complete)
plot(hclust.average)
plot(hclust.single)
pokemon <- read.delim("clipboard")
head(pokemon)
colMeans(pokemon)
apply(pokemon, 2, sd)
pokemon.scaled <- scale(pokemon)
hclust.pokemon <- hclust(dist(pokemon.scaled), method="complete")
plot(hclust.pokemon)
data = iris[,-5]
head(data)
km <- kmeans(data, centers = 3)
km
library(cluster)
data(xclara)
head(xclara)
km <- kmeans(xclara,3)
km
km$cl
sk <- silhouette(km$cl, dissE)
dissE <- daisy(xclara)
sk <- silhouette(km$cl, dissE)
plot(sk)
window()
windows()
plot(sk)
head(xclara)
dissE <- daisy(xclara)
sk <- silhouette(km$cl, dissE)
windows()
plot(sk)
km
km[1]
km[2]
km
km[5]
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1903/datasets/WisconsinCancer.csv"
wisc.df <- read.csv(url)
wisc.data[1:6, 1:5]
wisc.df[1:6, 1:5]
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1903/datasets/WisconsinCancer.csv"
wisc.df <- read.csv(url)
wisc.data <- as.matrix(wisc.df)
row.names(wisc.data) <- wisc.df$id
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
head(wisc.data)
wisc.data <- as.matrix(wisc.df[3:32])
row.names(wisc.data) <- wisc.df$id
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
head(wisc.data)
head(wisc.df)
dim(wisc.data)
colnames(wisc.data)
table(diagnosis)
grep("_mean", colnames(wisc.data))
length(grep("_mean", colnames(wisc.data)))
colnames(wisc.data)[(grep("_mean", colnames(wisc.data)))]
ls()
colMeans(wisc.data)
apply(wisc.data, 2, sd)
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
biplot(wisc.pr)
plot(wisc.pr$rotation[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$rotation[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$rotation[, c(1, 4)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC4")
biplot(wisc.pr)
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$x[, c(1, 4)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
par(mfrow = c(1, 2))
pr.var <- wisc.pr$sdev^2
pve <- pr.var/sum(pr.var)
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cummulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
wise.pr$rotation
wisc.pr$rotation[rownames(wisc.pr$rotation)=="concave.points_mean",]
wisc.pr$rotation[rownames(wisc.pr$rotation)=="concave.points_mean",][1]
round(colMeans(wisc.data),1)
round(apply(wisc.data,2,sd),1)
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist, method="complete")
round(colMeans(data.scaled),1)
round(apply(data.scaled,2,sd),1)
plot(wisc.hclust)
plot(wisc.hclust)
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
wisc.km <- kmeans(scale(wisc.data), centers=2, nstart=20)
table(wisc.km$cluster, diagnosis)
table(wisc.km$cluster, wisc.hclust.clusters)
pve <- pr.var/sum(pr.var)
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cummulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
summary(wisc.pr)
class(summary(wisc.pr))
pve
len(pve)
length(pve)
for(i in 1:length(pve)){
paste("Num of Components", i, "Variance", cumsum(pve[1:i]))
}
print(paste("Num of Components", i, "Variance", cumsum(pve[1:i])))
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", round(cumsum(pve[1:i]),1)))
}
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", round(cumsum(pve[1:i]))))
}
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", cumsum(pve[1:i])))
}
head(mtcars)
colMeans(mtcars)
data.frame(colMeans(mtcars))
apply(mtcars, 2, sd)
data.frame(apply(mtcars, 2, sd))
mtcars_scaled <- scale(mtcars)
head(mtcars_scaled)
data.frame(colMeans(mtcars_scaled))
data.frame(apply(mtcars_scaled, 2, sd))
center(mtcars)
?scale
new_text <- "DataCamp is the first online learning platform that focuses on building the best learning experience specifically for Data Science. We have offices in Boston and Belgium and to date, we trained over 250,000 (aspiring) data scientists in over 150 countries. These data science enthusiasts completed more than 9 million exercises. You can take free beginner courses, or subscribe for $25/month to get access to all premium courses."
library(qdap)
install.packages("qdap")
library(qdap)
library(qdap)
install.packages("qdapRegex")
library(qdapRegex)
library(qdap)
install.packages("‘qdapTools’")
library(qdapRegex)
library(qdap)
library(qdapTool)
library(qdapTools)
install.packages("qdapTools")
library(qdapRegex)
library(qdapTools)
library(qdap)
install.packages("qdap")
library(gender)
library(qdap)
print(new_text)
term_count <- freq_terms(new_text,10)
plot(term_count)
library(plyr)
a <- airquality
names(a)[colMeans(is.na(a))>0]
library(ROSE)
install.packages("ROSE")
data(hacide)
library(ROSE)
data(hacide)
str(hacide.train)
table(hacide.train$cls)
prop.table(table(hacide.train$cls))
treeimb <- rpart(cls ~ ., data = hacide.train)
library(rpart)
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test)
str(pred.treeimb)
summary(pred.treeimb)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F)
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = T)
pred.treeimb
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F)
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = T)
hacide.test$cls
head((hacide.train))
table(hacide.train$cls)
str(hacide.test)
head((hacide.test))
table(hacide.test$cls)
table(hacide.train$cls)
library(caret)
rfimb <- train(cls~., data=hacide.train)
str(hacide.train)
pred.rfimb <- predict(rfimb, newdata = hacide.test)
confusionMatrix(pred.treeimb[,2],hacide.test$cls)
accuracy.meas(hacide.test$cls, pred.rfimb[,2])
rm(list=ls())
library(ROSE)
data(hacide)
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test)
pred.treeimb
hacide.test
library(caret)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit
head(training)
head(testing)
pred <- predict(modFit,testing)
pred
head((hacide.train))
str(hacide.train)
rfimb <- train(cls~., method="rf",data=hacide.train)
pred.rfimb <- predict(rfimb, newdata = hacide.test)
pred.rfimb
accuracy.meas(hacide.test$cls, pred.rfimb)
roc.curve(hacide.test$cls, pred.treeimb, plotit = F)
dim(hacide.test$cls)
length(hacide.test$cls)
roc.curve(hacide.test$cls, pred.rfimb, plotit = F)
roc.curve(hacide.test$cls, pred.rfimb, plotit = T)
confusionMatrix(pred.rfimb,hacide.test$cls)
accuracy.meas(hacide.test$cls, pred.rfimb)
treeimb1 <- train(cls ~ .,method="rpart", data = hacide.train)
pred.treeimb1 <- predict(treeimb1, newdata = hacide.test)
pred.treeimb1
accuracy.meas(hacide.test$cls, pred.treeimb1)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
treeimb <- rpart(cls ~ ., data = hacide.train, type="class")
treeimb <- rpart(cls ~ ., data = hacide.train, type="class")
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test, tpye="class")
pred.treeimb
head(hacide.train)
head(hacide.test)
head(cbind(hacide.test$cls, pred.treeimb[,2]))
pred.treeimb
head(pred.treeimb)
confusionMatrix(hacide.test$cls, pred.treeimb[,2])
confusionMatrix(hacide.test$cls, pred.treeimb)
treeimb1 <- train(cls ~ .,method="rpart", data = hacide.train)
pred.treeimb1 <- predict(treeimb1, newdata = hacide.test)
treeimb_c <- train(cls ~ .,method="rpart", data = hacide.train)
pred.treeimb_c <- predict(treeimb1, newdata = hacide.test)
accuracy.meas(hacide.test$cls, pred.treeimb_c)
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = F) #Without Plot
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = T) #With Plot
confusionMatrix(pred.treeimb_c, hacide.test$cls)
accuracy.meas(pred.treeimb_c,hacide.test$cls)
accuracy.meas(hacide.test$cls, pred.treeimb_c)
confusionMatrix(pred.treeimb_c, hacide.test$cls)
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = F) #Without Plot
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = T) #With Plot
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test, tpye="class")
head(pred.treeimb)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F) #Without Plot
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = T) #With Plot
rfimb_c <- train(cls~., method="rf",data=hacide.train)
pred.rfimb_c <- predict(rfimb_c, newdata = hacide.test)
accuracy.meas(hacide.test$cls, pred.rfimb_c)
confusionMatrix(pred.rfimb_c, hacide.test$cls)
roc.curve(hacide.test$cls, pred.rfimb_c, plotit = F)
roc.curve(hacide.test$cls, pred.rfimb_c, plotit = T)
?randomForest
help(randomForest)
??randomForest
heat(mtcars)
head(mtcars)
library(dplyr)
library(ggplot2)
library(NHANES)
names(NHANES)
# Create bar plot for Home Ownership by Gender
ggplot(NHANES, aes(x = Gender, fill = HomeOwn)) +
geom_bar(position = "fill") +
ylab("Relative frequencies")
# Density for SleepHrsNight colored by SleepTrouble, faceted by HealthGen
ggplot(NHANES, aes(x =  SleepHrsNight, col = SleepTrouble)) +
geom_density(adjust=2) +
facet_wrap(~HealthGen)
#Testing
dim(NHANES)
# Subset the data: homes
homes <- NHANES %>%
select(Gender, HomeOwn) %>%
filter(HomeOwn %in% c("Own", "Rent"))
# Perform one permutation
homes %>%
mutate(HomeOwn_perm = sample(HomeOwn)) %>%
group_by(Gender) %>%
summarize(prop_own_perm = mean(HomeOwn_perm == "Own"),
prop_own = mean(HomeOwn == "Own")) %>%
summarize(diff_perm = diff(prop_own_perm),
diff_orig = diff(prop_own))
homeown_perm <- homes %>%
rep_sample_n(size = nrow(homes), reps = 100) %>%
mutate(HomeOwn_perm = sample(HomeOwn)) %>%
group_by(replicate,Gender) %>%
summarize(prop_own_perm = mean(HomeOwn_perm == "Own"),
prop_own = mean(HomeOwn == "Own")) %>%
summarize(diff_perm = diff(prop_own_perm),
diff_orig = diff(prop_own)) # male - female
library(devtools)
devtools::install_github("andrewpbray/oilabs")
library(oilabs)
library(oilabs)
# Perform 10 permutations
homeown_perm <- homes %>%
rep_sample_n(size = nrow(homes), reps = 10) %>%
mutate(HomeOwn_perm = sample(HomeOwn)) %>%
group_by(replicate,Gender) %>%
summarize(prop_own_perm = mean(HomeOwn_perm == "Own"),
prop_own = mean(HomeOwn == "Own")) %>%
summarize(diff_perm = diff(prop_own_perm),
diff_orig = diff(prop_own)) # male - female
# Print differences to console
print(homeown_perm)
# Dotplot of 10 permuted differences in proportions
ggplot(homeown_perm, aes(x = diff_perm)) +
geom_dotplot(binwidth = 0.001)
# Create bar plot for Home Ownership by Gender
ggplot(NHANES, aes(x = Gender, fill = HomeOwn)) +
geom_bar(position = "fill") +
ylab("Relative frequencies")
# Density for SleepHrsNight colored by SleepTrouble, faceted by HealthGen
ggplot(NHANES, aes(x =  SleepHrsNight, col = SleepTrouble)) +
geom_density(adjust=2) +
facet_wrap(~HealthGen)
homeown_perm <- homes %>%
rep_sample_n(size = nrow(homes), reps = 10) %>%
mutate(HomeOwn_perm = sample(HomeOwn)) %>%
group_by(replicate,Gender) %>%
summarize(prop_own_perm = mean(HomeOwn_perm == "Own"),
prop_own = mean(HomeOwn == "Own")) %>%
summarize(diff_perm = diff(prop_own_perm),
diff_orig = diff(prop_own)) # male - female
# Print differences to console
print(homeown_perm)
# Dotplot of 10 permuted differences in proportions
ggplot(homeown_perm, aes(x = diff_perm)) +
geom_dotplot(binwidth = 0.001)
disc <- read.table("disc.txt")
disc <- read.table("disc.txt")
getwd()
setwd("~/GitHub/LearningPython/Datacamp/R - Foundation of Inference")
disc <- read.table("disc.txt")
head(disc)
disc <- read.table("disc.txt", header = TRUE)
head(disc)
tail(disc)
table(disc)
disc %>% group_by(sex) %>% summarize(promoted_prop = mean(promote == "promoted"))
# Create a data frame of differences in promotion rates
disc_perm <- disc %>%
rep_sample_n(size = nrow(disc), reps = 1000) %>%
mutate(prom_perm = sample(promote)) %>%
group_by(replicate, sex) %>%
summarize(prop_prom_perm = mean(prom_perm=="promoted"),
prop_prom = mean(promote=="promoted"))   %>%
summarize(diff_perm = diff(prop_prom_perm),
diff_orig = diff(prop_prom))  # male - female
# Histogram of permuted differences
ggplot(disc_perm, aes(x = diff_perm)) +
geom_histogram(binwidth = 0.01) +
geom_vline(aes(xintercept = diff_orig), col = "red")
