carriers <- hflights$UniqueCarrier
str(hflights)
two <- c("AA", "AS")
lut <- c("AA" = "American",
"AS" = "Alaska",
"B6" = "JetBlue")
lut
two <- lut[two]
two
# Both the dplyr and hflights packages are loaded into workspace
lut <- c("AA" = "American", "AS" = "Alaska", "B6" = "JetBlue", "CO" = "Continental",
"DL" = "Delta", "OO" = "SkyWest", "UA" = "United", "US" = "US_Airways",
"WN" = "Southwest", "EV" = "Atlantic_Southeast", "F9" = "Frontier",
"FL" = "AirTran", "MQ" = "American_Eagle", "XE" = "ExpressJet", "YV" = "Mesa")
# Add the Carrier column to hflights
hflights$Carrier <- lut[hflights$UniqueCarrier]
# Glimpse at hflights
glimpse(hflights)
?hflights
library(psych)
bmi_cc <- read.clipboard()
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.delim("clipboard")
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.delim("clipboard")
bmi_cc
names(bmi_cc)
bmi_cc <- read.delim("clipboard", sep = " ")
bmi_cc <- read.delim("clipboard", sep = " ",header = TRUE)
bmi_cc <- read.delim("clipboard", sep = " ",header = TRUE)
bmi_cc
bmi_cc <- read.delim("clipboard",header = TRUE)
bmi_cc <- read.clipboard(header = TRUE)
bmi_cc <- read.delim("clipboard",header = TRUE)
bmi_cc
library(tidyr)
separate(bmi_cc, Country_ISO..year..bmi_val, c("Country_ISO","year","bmi_val"))
separate(bmi_cc, Country_ISO..year..bmi_val, c("Country_ISO","year","bmi_val"), sep="...")
library(ggplot2)
data(diamonds)
head(diamonds)
str(diamonds)
q()
library (cluster)
library (vegan)
install.packages("vegan")
library (vegan)
data(varespec)
head(varespec)
dis = vegdist(varespec)
res = pam(dis,3) # or whatever your choice of clustering algorithm is
sil = silhouette (res$clustering,dis) # or use your cluster vector
plot(sil)
windows() # RStudio sometimes does not display silhouette plots correctly
plot(sil)
library (vegan)
library (cluster)
data(varespec)
dis = dist(varespec)^2
km <- kmeans(data, centers = 3)
data = iris[,-5]
km <- kmeans(data, centers = 3)
km
wss <- 0
for (i in 1:15) {
km.out <- kmeans(data, centers = i, nstart=20)
# Save total within sum of squares to wss variable
wss[i] <- km.out$tot.withinss
}
plot(1:15, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within groups sum of squares")
data = mtcars
wss <- 0
for (i in 1:15) {
km.out <- kmeans(data, centers = i, nstart=20)
# Save total within sum of squares to wss variable
wss[i] <- km.out$tot.withinss
}
plot(1:15, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within groups sum of squares")
head(data)
clip <- read.delim("clipboard")
head(clip)
rownames(clip)
class(clip)
clip <- read.delim("clipboard")
head(clip)
rownames(clip)
class(clip)
x <- read.delim("clipboard")
x
names(x)
hclust.complete <- hclust(dist(x), method="complete")
x <- read.delim("clipboard")
x
x <- read.delim("clipboard")
x
names(x)
x <- read.delim("clipboard")
x
names(x)
hclust.complete <- hclust(dist(x), method="complete")
hclust.average <- hclust(dist(x), method="average")
hclust.single <- hclust(dist(x), method="single")
plot(hclust.complete)
plot(hclust.average)
plot(hclust.single)
plot(hclust.complete)
plot(hclust.average)
plot(hclust.single)
pokemon <- read.delim("clipboard")
head(pokemon)
colMeans(pokemon)
apply(pokemon, 2, sd)
pokemon.scaled <- scale(pokemon)
hclust.pokemon <- hclust(dist(pokemon.scaled), method="complete")
plot(hclust.pokemon)
data = iris[,-5]
head(data)
km <- kmeans(data, centers = 3)
km
library(cluster)
data(xclara)
head(xclara)
km <- kmeans(xclara,3)
km
km$cl
sk <- silhouette(km$cl, dissE)
dissE <- daisy(xclara)
sk <- silhouette(km$cl, dissE)
plot(sk)
window()
windows()
plot(sk)
head(xclara)
dissE <- daisy(xclara)
sk <- silhouette(km$cl, dissE)
windows()
plot(sk)
km
km[1]
km[2]
km
km[5]
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1903/datasets/WisconsinCancer.csv"
wisc.df <- read.csv(url)
wisc.data[1:6, 1:5]
wisc.df[1:6, 1:5]
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1903/datasets/WisconsinCancer.csv"
wisc.df <- read.csv(url)
wisc.data <- as.matrix(wisc.df)
row.names(wisc.data) <- wisc.df$id
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
head(wisc.data)
wisc.data <- as.matrix(wisc.df[3:32])
row.names(wisc.data) <- wisc.df$id
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
head(wisc.data)
head(wisc.df)
dim(wisc.data)
colnames(wisc.data)
table(diagnosis)
grep("_mean", colnames(wisc.data))
length(grep("_mean", colnames(wisc.data)))
colnames(wisc.data)[(grep("_mean", colnames(wisc.data)))]
ls()
colMeans(wisc.data)
apply(wisc.data, 2, sd)
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
biplot(wisc.pr)
plot(wisc.pr$rotation[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$rotation[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$rotation[, c(1, 4)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC4")
biplot(wisc.pr)
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$x[, c(1, 4)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
plot(wisc.pr$x[, c(1, 2)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC2")
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1),
xlab = "PC1", ylab = "PC3")
par(mfrow = c(1, 2))
pr.var <- wisc.pr$sdev^2
pve <- pr.var/sum(pr.var)
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cummulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
wise.pr$rotation
wisc.pr$rotation[rownames(wisc.pr$rotation)=="concave.points_mean",]
wisc.pr$rotation[rownames(wisc.pr$rotation)=="concave.points_mean",][1]
round(colMeans(wisc.data),1)
round(apply(wisc.data,2,sd),1)
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist, method="complete")
round(colMeans(data.scaled),1)
round(apply(data.scaled,2,sd),1)
plot(wisc.hclust)
plot(wisc.hclust)
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
wisc.km <- kmeans(scale(wisc.data), centers=2, nstart=20)
table(wisc.km$cluster, diagnosis)
table(wisc.km$cluster, wisc.hclust.clusters)
pve <- pr.var/sum(pr.var)
plot(cumsum(pve), xlab = "Principal Component",
ylab = "Cummulative Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
summary(wisc.pr)
class(summary(wisc.pr))
pve
len(pve)
length(pve)
for(i in 1:length(pve)){
paste("Num of Components", i, "Variance", cumsum(pve[1:i]))
}
print(paste("Num of Components", i, "Variance", cumsum(pve[1:i])))
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", round(cumsum(pve[1:i]),1)))
}
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", round(cumsum(pve[1:i]))))
}
for(i in 1:length(pve)){
print(paste("Num of Components", i, "Variance", cumsum(pve[1:i])))
}
head(mtcars)
colMeans(mtcars)
data.frame(colMeans(mtcars))
apply(mtcars, 2, sd)
data.frame(apply(mtcars, 2, sd))
mtcars_scaled <- scale(mtcars)
head(mtcars_scaled)
data.frame(colMeans(mtcars_scaled))
data.frame(apply(mtcars_scaled, 2, sd))
center(mtcars)
?scale
new_text <- "DataCamp is the first online learning platform that focuses on building the best learning experience specifically for Data Science. We have offices in Boston and Belgium and to date, we trained over 250,000 (aspiring) data scientists in over 150 countries. These data science enthusiasts completed more than 9 million exercises. You can take free beginner courses, or subscribe for $25/month to get access to all premium courses."
library(qdap)
install.packages("qdap")
library(qdap)
library(qdap)
install.packages("qdapRegex")
library(qdapRegex)
library(qdap)
install.packages("‘qdapTools’")
library(qdapRegex)
library(qdap)
library(qdapTool)
library(qdapTools)
install.packages("qdapTools")
library(qdapRegex)
library(qdapTools)
library(qdap)
install.packages("qdap")
library(gender)
library(qdap)
print(new_text)
term_count <- freq_terms(new_text,10)
plot(term_count)
library(plyr)
a <- airquality
names(a)[colMeans(is.na(a))>0]
library(ROSE)
install.packages("ROSE")
data(hacide)
library(ROSE)
data(hacide)
str(hacide.train)
table(hacide.train$cls)
prop.table(table(hacide.train$cls))
treeimb <- rpart(cls ~ ., data = hacide.train)
library(rpart)
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test)
str(pred.treeimb)
summary(pred.treeimb)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F)
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = T)
pred.treeimb
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F)
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = T)
hacide.test$cls
head((hacide.train))
table(hacide.train$cls)
str(hacide.test)
head((hacide.test))
table(hacide.test$cls)
table(hacide.train$cls)
library(caret)
rfimb <- train(cls~., data=hacide.train)
str(hacide.train)
pred.rfimb <- predict(rfimb, newdata = hacide.test)
confusionMatrix(pred.treeimb[,2],hacide.test$cls)
accuracy.meas(hacide.test$cls, pred.rfimb[,2])
rm(list=ls())
library(ROSE)
data(hacide)
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test)
pred.treeimb
hacide.test
library(caret)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit
head(training)
head(testing)
pred <- predict(modFit,testing)
pred
head((hacide.train))
str(hacide.train)
rfimb <- train(cls~., method="rf",data=hacide.train)
pred.rfimb <- predict(rfimb, newdata = hacide.test)
pred.rfimb
accuracy.meas(hacide.test$cls, pred.rfimb)
roc.curve(hacide.test$cls, pred.treeimb, plotit = F)
dim(hacide.test$cls)
length(hacide.test$cls)
roc.curve(hacide.test$cls, pred.rfimb, plotit = F)
roc.curve(hacide.test$cls, pred.rfimb, plotit = T)
confusionMatrix(pred.rfimb,hacide.test$cls)
accuracy.meas(hacide.test$cls, pred.rfimb)
treeimb1 <- train(cls ~ .,method="rpart", data = hacide.train)
pred.treeimb1 <- predict(treeimb1, newdata = hacide.test)
pred.treeimb1
accuracy.meas(hacide.test$cls, pred.treeimb1)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
treeimb <- rpart(cls ~ ., data = hacide.train, type="class")
treeimb <- rpart(cls ~ ., data = hacide.train, type="class")
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test, tpye="class")
pred.treeimb
head(hacide.train)
head(hacide.test)
head(cbind(hacide.test$cls, pred.treeimb[,2]))
pred.treeimb
head(pred.treeimb)
confusionMatrix(hacide.test$cls, pred.treeimb[,2])
confusionMatrix(hacide.test$cls, pred.treeimb)
treeimb1 <- train(cls ~ .,method="rpart", data = hacide.train)
pred.treeimb1 <- predict(treeimb1, newdata = hacide.test)
treeimb_c <- train(cls ~ .,method="rpart", data = hacide.train)
pred.treeimb_c <- predict(treeimb1, newdata = hacide.test)
accuracy.meas(hacide.test$cls, pred.treeimb_c)
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = F) #Without Plot
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = T) #With Plot
confusionMatrix(pred.treeimb_c, hacide.test$cls)
accuracy.meas(pred.treeimb_c,hacide.test$cls)
accuracy.meas(hacide.test$cls, pred.treeimb_c)
confusionMatrix(pred.treeimb_c, hacide.test$cls)
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = F) #Without Plot
roc.curve(hacide.test$cls, pred.treeimb_c, plotit = T) #With Plot
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test, tpye="class")
head(pred.treeimb)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F) #Without Plot
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = T) #With Plot
rfimb_c <- train(cls~., method="rf",data=hacide.train)
pred.rfimb_c <- predict(rfimb_c, newdata = hacide.test)
accuracy.meas(hacide.test$cls, pred.rfimb_c)
confusionMatrix(pred.rfimb_c, hacide.test$cls)
roc.curve(hacide.test$cls, pred.rfimb_c, plotit = F)
roc.curve(hacide.test$cls, pred.rfimb_c, plotit = T)
?randomForest
help(randomForest)
??randomForest
library(stringr)
?str_view
awards <- c("Won 1 Oscar.",
"Won 1 Oscar. Another 9 wins & 24 nominations.",
"1 win and 2 nominations.",
"2 wins & 3 nominations.",
"Nominated for 2 Golden Globes. 1 more win & 2 nominations.",
"4 wins & 1 nomination.")
awards
str_view(awards, pattern=".*\\s([0-9]+)\\snomination.*$")
?regex
str_view(awards, pattern=".*\\s([0-9]+)\\snomination.*$")
str_view(awards, pattern="&.*\\s([0-9]+)\\snomination.*$")
str_view(awards, pattern=".\\s([0-9]+)\\snomination.*$")
str_view(awards, pattern="\\s([0-9]+)\\snomination.*$")
awards <- c("Won 1 Oscar.",
"Won 1 Oscar. Another 9 wins & 24 nominations.",
"1 win and 2 nominations.",
"2 wins & 3 nominations.",
"Nominated for 2 Golden Globes. 1 more win & 2 nominations.",
"4 wins & 1 nomination.")
awards
str_view(awards, pattern=".*\\s([0-9]+)\\snomination.*$")
str_view(awards, pattern="\\s([0-9]+)\\snomination.*$")
str_view(awards, pattern="&.*\\s([0-9]+)\\snomination.*$")
# Get the current date: today
today <- Sys.Date()
# See what today looks like under the hood
unclass(today)
# Get the current time: now
now <- Sys.time()
# See what now looks like under the hood
unclass(now)
# Definition of character strings representing times
str1 <- "May 23, '96 hours:23 minutes:01 seconds:45"
str2 <- "2012-3-12 14:23:08"
# Convert the strings to POSIXct objects: time1, time2
time1 <- as.POSIXct(str1, format = "%B %d, '%y hours:%H minutes:%M seconds:%S")
time2 <- as.POSIXct(str2, format = "%Y-%m-%d %H:%M:%S")
# Convert times to formatted strings
format(time1, "%M")
format(time2, "%I:%M %p")
c(day1, day2, day3, day4, day5) <- c("2017-05-01" ,"2017-05-03", "2017-05-08" ,"2017-05-14" ,"2017-05-19")
day1 =as.Date("2017-05-01")
day2 =as.Date("2017-05-03")
day3 =as.Date("2017-05-08")
day4 =as.Date("2017-05-14")
day5 =as.Date("2017-05-19")
day5-day1
pizza <- c(day1, day2, day3, day4, day5)
day_diff <- diff(pizza)
mean(day_diff)
astro <- c("20-Mar-2015", "25-Jun-2015", "23-Sep-2015", "22-Dec-2015")
names(astro) <- c('spring'  ,     'summer',          'fall'  ,      'winter')
astro
meteo = c("March 1, 15",      "June 1, 15" ,"September 1, 15" , "December 1, 15")
names(meteo)=c('spring'   ,         'summer'        ,      'fall'  ,          'winter')
meteo
astro_dates <- as.Date(astro, "%d-%b-%Y")
meteo_dates <- as.Date(meteo, "%B %d, %y")
print(max(abs(astro_dates-meteo_dates)))
p1 = 0.64
p2 = 0.36
p1(1-p1) + p2(1-p2)
p1 = 0.64
p2 = 0.36
p1(1-p1) + p2(1-p2)
p1 <- 0.64
p2  <- 0.36
p1(1-p1) + p2(1-p2)
p1(1-p1)
p1
p1*(1-p1) + p2*(1-p2)
- p1*log(p1) - p2*log(p2)
p1*(1-p1) + p2*(1-p2)
- p1*log(p1) - p2*log(p2)
0.1+0.15+0.2+0.2+0.55+0.6+0.6+0.65+0.7+0.75
?dt
x <- seq(-4, 4, length = 100)
y_1 <- dt(x, df = 4)
y_2 <- dt(x, df = 6)
y_3 <- dt(x, df = 8)
y_4 <- dt(x, df = 10)
y_5 <- dt(x, df = 12)
plot(x, y_1, type = "l", lwd = 2, xlab = "t-value", ylab = "Density",
main = "Comparison of t-distributions", col = "black")
lines(x, y_2, col = "red")
lines(x, y_3, col = "orange")
lines(x, y_4, col = "green")
lines(x, y_5, col = "blue")
legend("topright", c("df = 4", "df = 6", "df = 8", "df = 10", "df = 12"),
col = c("black", "red", "orange", "green", "blue"),
title = "t-distributions", lty = 1)
wm <- read.table("wm.txt")
getwd()
setwd("~/GitHub/LearningPython/Datacamp/R - Intro to Statistics with R Student's T-test")
wm <- read.table("wm.txt")
wm
wm <- read.table("wm.txt", header=TRUE)
wm
wm_t <- subset(wm, train==1)
describe(wm_t)
describe(wm_t)
library(psych)
library(psych)
describe(wm_t)
boxplot(wm_t$pre, wm_t$post, main = "Boxplot",
xlab = "Pre- and Post-Training" , ylab = "Intelligence Score",
col = c("red", "green"))
?qt
t_crit <- qt(0.975, 79)
print(t_crit)
print(t_obs)
n <- nrow(wm_t)
# Mean of the difference scores
mean_diff <- sum(wm_t$gain)/n
# Standard deviation of the difference scores
sd_diff <- sqrt(sum((wm_t$gain - mean_diff)^2) / (n-1))
# Observed t-value
t_obs <- mean_diff / (sd_diff / sqrt(n))
# Print observed t-value
print(t_obs)
print(t_obs)
cohens_d <- mean_diff/sd_diff
cohens_d
